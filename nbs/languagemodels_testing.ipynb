{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch\n",
    "import string\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertForMaskedLM.from_pretrained('bert-base-uncased').eval()\n",
    "\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForMaskedLM\n",
    "xlmroberta_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "xlmroberta_model = XLMRobertaForMaskedLM.from_pretrained('xlm-roberta-base').eval()\n",
    "\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large').eval()\n",
    "\n",
    "from transformers import ElectraTokenizer, ElectraForMaskedLM\n",
    "electra_tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-generator')\n",
    "electra_model = ElectraForMaskedLM.from_pretrained('google/electra-small-generator').eval()\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaForMaskedLM.from_pretrained('roberta-base').eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "\n",
    "model_dict = {'bert':(bert_tokenizer, bert_model),'xlmroberta':(xlmroberta_tokenizer, xlmroberta_model),\n",
    "              'bart':(bart_tokenizer, bart_model),'electra': (electra_tokenizer, electra_model),\n",
    "              'roberta': (roberta_tokenizer, roberta_model)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(tokenizer, pred_idx, top_clean):\n",
    "    ignore_tokens = string.punctuation + '[PAD]'\n",
    "    tokens = []\n",
    "    for w in pred_idx:\n",
    "        token = ''.join(tokenizer.decode(w).split())\n",
    "        if token not in ignore_tokens:\n",
    "            tokens.append(token.replace('##', ''))\n",
    "    return tokens[:top_clean]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_multiple_masks(tokenizer, predict, mask_positions, fillinblank_sentences, top_clean):\n",
    "    # Place the predictions in the sentence\n",
    "    for mask_idx in mask_positions:\n",
    "        predicted_words = decode(tokenizer, predict[0, mask_idx, :].topk(top_k).indices.tolist(), top_clean)\n",
    "        print(\"Predicted words are \", predicted_words)\n",
    "        for idx in range((len(predicted_words))):\n",
    "            fillinblank_sentences[idx][mask_idx] = predicted_words[idx]\n",
    "    return fillinblank_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(tokenizer, text_sentence, add_special_tokens=True):\n",
    "    text_sentence = text_sentence.replace('<mask>', tokenizer.mask_token)\n",
    "    # if <mask> is the last token, append a \".\" so that models dont predict punctuation.\n",
    "    if tokenizer.mask_token == text_sentence.split()[-1]:\n",
    "        text_sentence += ' .'\n",
    "    \n",
    "    input_ids = torch.tensor([tokenizer.encode(text_sentence, add_special_tokens=add_special_tokens)])\n",
    "    mask_positions = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()\n",
    "\n",
    "    return input_ids, mask_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(modelname, text_sentence, top_clean=5):\n",
    "    \"\"\"\n",
    "    Psuedocode:\n",
    "        Get the masked sentence.\n",
    "        Encode it & pass it through model\n",
    "        Now, decode at each position.\n",
    "    \"\"\"\n",
    "    results = dict()\n",
    "    tokenizer, model = model_dict[modelname]\n",
    "    input_ids, mask_positions = encode(tokenizer, text_sentence)\n",
    "    fillinblank_sentences = []\n",
    "\n",
    "    \"\"\"\n",
    "    Create fill in the blanks to fill up \n",
    "    with predictions in the later stage\n",
    "    \"\"\"\n",
    "    for _ in range(top_clean):\n",
    "        predicted_sentence = [tokenn.replace('Ġ','') for tokenn in tokenizer.convert_ids_to_tokens(li)]\n",
    "        fillinblank_sentences.append(predicted_sentence)\n",
    "\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        predict = model(input_ids)[0]\n",
    "\n",
    "    # Place the predictions in the sentence\n",
    "    results = decode_multiple_masks(tokenizer, predict, mask_positions, fillinblank_sentences, top_clean)\n",
    "    return results, mask_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'ĠCompany',\n",
       " 'Ġunderstands',\n",
       " 'Ġand',\n",
       " 'Ġaccepts',\n",
       " '<mask>',\n",
       " 'Ġapology',\n",
       " '</s>']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_tokenizer.decode([0,1260,8832,8,14564,50264, 9664,2], clean_up_tokenization_spaces=False)\n",
    "li = [0,1260,8832,8,14564,50264, 9664,2]\n",
    "roberta_tokenizer.convert_ids_to_tokens(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode function input is Company understands and accepts <mask> apology\n",
      "<transformers.tokenization_roberta.RobertaTokenizer object at 0x0000024BF8207B20>\n",
      "Predicted words are  ['our', 'the', 'their', 'your', 'this']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['<s>',\n",
       "   'Company',\n",
       "   'understands',\n",
       "   'and',\n",
       "   'accepts',\n",
       "   'our',\n",
       "   'apology',\n",
       "   '</s>'],\n",
       "  ['<s>',\n",
       "   'Company',\n",
       "   'understands',\n",
       "   'and',\n",
       "   'accepts',\n",
       "   'the',\n",
       "   'apology',\n",
       "   '</s>'],\n",
       "  ['<s>',\n",
       "   'Company',\n",
       "   'understands',\n",
       "   'and',\n",
       "   'accepts',\n",
       "   'their',\n",
       "   'apology',\n",
       "   '</s>'],\n",
       "  ['<s>',\n",
       "   'Company',\n",
       "   'understands',\n",
       "   'and',\n",
       "   'accepts',\n",
       "   'your',\n",
       "   'apology',\n",
       "   '</s>'],\n",
       "  ['<s>',\n",
       "   'Company',\n",
       "   'understands',\n",
       "   'and',\n",
       "   'accepts',\n",
       "   'this',\n",
       "   'apology',\n",
       "   '</s>']],\n",
       " [5])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions('roberta','Company understands and accepts <mask> apology',  5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_sentence(tokens, tokenizer, style='bert'):\n",
    "    \"\"\"\n",
    "    Reference: https://github.com/huggingface/transformers/blob/f9cde97b313c3218e1b29ea73a42414dfefadb40/examples/lm_finetuning/simple_lm_finetuning.py#L267\n",
    "\n",
    "    Masking some random tokens for Language Model task with probabilities as in the original BERT paper.\n",
    "    :param tokens: list of str, tokenized sentence.\n",
    "    :param tokenizer: Tokenizer, object used for tokenization (we need it's vocab here)\n",
    "    :return: (list of str, list of int), masked tokens and related labels for LM prediction\n",
    "\n",
    "    Replace some with <mask>, some with random words.\n",
    "    \"\"\"\n",
    "    output_label = []\n",
    "    # mask_positions = [] # For storing the position where words are changed\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        prob = random.random()\n",
    "        # mask token with 15% probability\n",
    "        if prob < 0.15:\n",
    "            prob /= 0.15\n",
    "\n",
    "            # 80% randomly change token to mask token\n",
    "            if prob < 0.8:\n",
    "                tokens[i] = \"<mask>\"\n",
    "\n",
    "            # 10% randomly change token to random token\n",
    "            # elif prob < 0.9:\n",
    "            #     tokens[i] = random.choice(list(tokenizer.vocab.items()))[0]\n",
    "\n",
    "            # -> rest 10% randomly keep current token\n",
    "\n",
    "            # append current token to output (we will predict these later)\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                output_label.append(tokenizer.convert_tokens_to_ids(token))\n",
    "            except KeyError:\n",
    "                # For unknown words (should not occur with BPE vocab)\n",
    "                output_label.append(tokenizer.convert_tokens_to_ids(\"[UNK]\"))\n",
    "                print(\"Cannot find token '{}' in vocab. Using [UNK] insetad\".format(token))\n",
    "        else:\n",
    "            # no masking token (will be ignored by loss function later)\n",
    "            output_label.append(-1)\n",
    "\n",
    "    return tokens, output_label \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input( tokenizer: object, style:str, text: str):\n",
    "    \"\"\"\n",
    "    Psuedocode:\n",
    "    * Tokenize the sentence.\n",
    "    * Send it to mask_sentence() -> Get the masked sentence and a\n",
    "      list. This list will have Indices numbers for positions\n",
    "      where masking is done.\n",
    "    * Convert sentences to ids.\n",
    "\n",
    "    Input : \n",
    "        :param -> tokenizer (transformer's object)\n",
    "        :style -> Masking style\n",
    "        :text  -> Sentence\n",
    "    Return: \n",
    "        :param -> Masked sentence, \n",
    "        :param -> Mask labels\n",
    "    \"\"\"\n",
    "    # Tokenize input\n",
    "\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    tokenized_text_ = copy.copy(tokenized_text)\n",
    "    masktokenized_text, mask_labels = mask_sentence(tokenized_text_, tokenizer, style=style)\n",
    "\n",
    "    # Convert token to vocabulary indices\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(masktokenized_text)\n",
    "\n",
    "    # Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "    # segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "    segments_ids = [0]* len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    input_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "                \n",
    "    # return tokenized_text, masktokenized_text, input_tensor,\\\n",
    "    #         mask_labels, segments_tensors\n",
    "    return masktokenized_text, mask_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_predictions(sentence: str, modelname: str, num_sents= 5):\n",
    "    \"\"\"\n",
    "    Psuedocode:\n",
    "    For each model,\n",
    "        * Mask the sentence\n",
    "        * Stitch it to a normal sentence (undo BPE). TODO\n",
    "        * Send it through the model\n",
    "    \"\"\"\n",
    "    masktokenized_text = ''\n",
    "    results = dict()\n",
    "\n",
    "    while '<mask>' not in masktokenized_text:\n",
    "        masktokenized_text, _ = prepare_input(tokenizer=model_dict[modelname][0], \\\n",
    "                                                        style=f'{modelname}', text=sentence)\n",
    "        masktokenized_text = [tokenn.replace('Ġ','') for tokenn in masktokenized_text]\n",
    "        \n",
    "    masked_sentence = ' '.join(masktokenized_text)\n",
    "\n",
    "    # Adding 1 for every position since <CLS> & <SEP> are added at encode stage.\n",
    "    pred_sents, mask_positions = get_predictions(modelname, masked_sentence, top_clean=num_sents)\n",
    "\n",
    "    #Add html tags to it\n",
    "    for idx, sent in enumerate(pred_sents):\n",
    "        for pos in mask_positions:\n",
    "            pred_sents[idx][pos] =  \"<p style='color:blue; display:inline'><b>\" + pred_sents[idx][pos] + \"</b></p>\"\n",
    "    \n",
    "    pred_sentences = [' '.join(sent[1:-1]) for sent in pred_sents]  #remove the cls and sep tag\n",
    "    results[modelname] = \"<br>\".join(pred_sentences)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode function input is Company understands and accepts the <mask> .\n",
      "<transformers.tokenization_roberta.RobertaTokenizer object at 0x0000024BF8207B20>\n",
      "Predicted words are  ['decision', 'apology', 'differences', 'above', 'judgment']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roberta': \"Company understands and accepts <mask> <p style='color:blue; display:inline'><b>decision</b></p><br>Company understands and accepts <mask> <p style='color:blue; display:inline'><b>apology</b></p><br>Company understands and accepts <mask> <p style='color:blue; display:inline'><b>differences</b></p><br>Company understands and accepts <mask> <p style='color:blue; display:inline'><b>above</b></p><br>Company understands and accepts <mask> <p style='color:blue; display:inline'><b>judgment</b></p>\"}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Company understands and accepts the apology'\n",
    "modelname = 'roberta'\n",
    "topk=5\n",
    "get_mask_predictions(sentence, modelname, topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode function input is Company understands and accepts <mask> apology\n",
      "<transformers.tokenization_roberta.RobertaTokenizer object at 0x0000024BF8207B20>\n",
      "Predicted words are  ['our', 'the', 'their', 'your', 'this']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['<s>',\n",
       "   'Company',\n",
       "   'understands',\n",
       "   'and',\n",
       "   'accepts',\n",
       "   'our',\n",
       "   'apology',\n",
       "   '</s>'],\n",
       "  ['<s>',\n",
       "   'Company',\n",
       "   'understands',\n",
       "   'and',\n",
       "   'accepts',\n",
       "   'the',\n",
       "   'apology',\n",
       "   '</s>'],\n",
       "  ['<s>',\n",
       "   'Company',\n",
       "   'understands',\n",
       "   'and',\n",
       "   'accepts',\n",
       "   'their',\n",
       "   'apology',\n",
       "   '</s>'],\n",
       "  ['<s>',\n",
       "   'Company',\n",
       "   'understands',\n",
       "   'and',\n",
       "   'accepts',\n",
       "   'your',\n",
       "   'apology',\n",
       "   '</s>'],\n",
       "  ['<s>',\n",
       "   'Company',\n",
       "   'understands',\n",
       "   'and',\n",
       "   'accepts',\n",
       "   'this',\n",
       "   'apology',\n",
       "   '</s>']],\n",
       " [5])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions('roberta','Company understands and accepts <mask> apology',  5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21960"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_tokenizer.convert_tokens_to_ids('Company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_aug] *",
   "language": "python",
   "name": "conda-env-data_aug-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
